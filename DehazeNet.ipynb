{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate\n",
    "from keras.applications import VGG16\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import mean_squared_error\n",
    "\n",
    "def build_dehaze_net(input_shape, output_channels):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    # Decoder\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
    "    up1 = UpSampling2D(size=(2, 2))(conv4)\n",
    "\n",
    "    concat1 = Concatenate()([conv3, up1])\n",
    "    conv5 = Conv2D(256, 3, activation='relu', padding='same')(concat1)\n",
    "    conv5 = Conv2D(256, 3, activation='relu', padding='same')(conv5)\n",
    "    up2 = UpSampling2D(size=(2, 2))(conv5)\n",
    "\n",
    "    concat2 = Concatenate()([conv2, up2])\n",
    "    conv6 = Conv2D(128, 3, activation='relu', padding='same')(concat2)\n",
    "    conv6 = Conv2D(128, 3, activation='relu', padding='same')(conv6)\n",
    "    up3 = UpSampling2D(size=(2, 2))(conv6)\n",
    "\n",
    "    concat3 = Concatenate()([conv1, up3])\n",
    "    conv7 = Conv2D(64, 3, activation='relu', padding='same')(concat3)\n",
    "    conv7 = Conv2D(64, 3, activation='relu', padding='same')(conv7)\n",
    "\n",
    "    # Output\n",
    "    output = Conv2D(output_channels, 1, activation='sigmoid', padding='same')(conv7)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    return model\n",
    "\n",
    "# Load images from multiple folders\n",
    "def load_images(image_folders, desired_shape):\n",
    "    images = []\n",
    "    for folder in image_folders:\n",
    "        image_names = os.listdir(folder)\n",
    "        for image_name in image_names:\n",
    "            image_path = os.path.join(folder, image_name)\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is not None:\n",
    "                image = cv2.resize(image, desired_shape[::-1])  # Reverse the order for (width, height)\n",
    "                images.append(image)\n",
    "    return images\n",
    "\n",
    "# Paths for foggy images and corresponding clear images in multiple folders\n",
    "foggy_images_folders = ['C:/Users/rahei/OneDrive/Desktop/archive/Foggy', 'C:/Users/rahei/OneDrive/Desktop/archive/Foggy 2-20230724T025947Z-001','C:/Users/rahei/OneDrive/Desktop/archive/Foggy-20230724T025946Z-001']\n",
    "clear_images_folders = ['C:/Users/rahei/OneDrive/Desktop/archive/Clear', 'C:/Users/rahei/OneDrive/Desktop/archive/Clear 2-20230724T025949Z-001','C:/Users/rahei/OneDrive/Desktop/archive/Clear-20230724T025952Z-001']\n",
    "\n",
    "# Load foggy and clear images from multiple folders\n",
    "desired_shape = (480, 640)  # Updated desired shape\n",
    "foggy_images = load_images(foggy_images_folders, desired_shape)\n",
    "clear_images = load_images(clear_images_folders, desired_shape)\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "foggy_images = np.array(foggy_images)\n",
    "clear_images = np.array(clear_images)\n",
    "\n",
    "# Normalize images to [0, 1] range\n",
    "foggy_images = foggy_images.astype('float32') / 255.0\n",
    "clear_images = clear_images.astype('float32') / 255.0\n",
    "\n",
    "# Build the dehazing model\n",
    "input_shape = foggy_images.shape[1:]  # Shape of one input sample (excluding batch size)\n",
    "output_channels = foggy_images.shape[-1]  # Number of output channels (RGB: 3)\n",
    "model = build_dehaze_net(input_shape, output_channels)\n",
    "\n",
    "# Perceptual loss using VGG16 features\n",
    "vgg = VGG16(include_top=False, weights='imagenet', input_shape=(480, 640, 3))  # Update input shape\n",
    "vgg.trainable = False\n",
    "output_layer = vgg.get_layer('block3_conv3').output\n",
    "vgg_model = Model(vgg.input, output_layer)\n",
    "\n",
    "def perceptual_loss(y_true, y_pred):\n",
    "    y_true_features = vgg_model(y_true)\n",
    "    y_pred_features = vgg_model(y_pred)\n",
    "    return mean_squared_error(y_true_features, y_pred_features)\n",
    "\n",
    "# Compile the model with Adam optimizer and perceptual loss\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss=perceptual_loss)\n",
    "# Train the model\n",
    "model.fit(foggy_images, clear_images, batch_size=32, epochs=250, validation_split=0.1)\n",
    "\n",
    "# Save the trained model\n",
    "model.save('C:/Users/rahei/OneDrive/Desktop/archive/dehaze_model_Color_Saver_250_2.5.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
