{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "IMAGE NAME FORMATTING TO BE THE SAME\n",
    "\"\"\"\n",
    "\n",
    "#DON'T RUN THIS CODE AGAIN -- ALREADY DONE \n",
    "\n",
    "import os\n",
    "\n",
    "U_folder = \"C:/Users/HP/Documents/Semester (summer)/Aim Lab Internship/Multi fog/U/\"  # Folder containing the  U images\n",
    "Utarget_folder = \"C:/Users/HP/Documents/Semester (summer)/Aim Lab Internship/Multi fog/U/\"  # Folder to save the converted images\n",
    "\n",
    "L_folder = \"C:/Users/HP/Documents/Semester (summer)/Aim Lab Internship/Multi fog/L/\"  # Folder containing the  L images\n",
    "Ltarget_folder = \"C:/Users/HP/Documents/Semester (summer)/Aim Lab Internship/Multi fog/L/\"  # Folder to save the converted images\n",
    "\n",
    "Llma_folder = \"C:/Users/HP\\Documents/Semester (summer)/Aim Lab Internship/Multi fog/Llma/\"  # Folder containing the  Llma images\n",
    "Llmatarget_folder = \"C:/Users/HP/Documents/Semester (summer)/Aim Lab Internship/Multi fog/Llma/\"  # Folder to save the converted images\n",
    "\n",
    "M_folder = \"C:/Users/HP/Documents/Semester (summer)/Aim Lab Internship/Multi fog/M/\"  # Folder containing the  M images\n",
    "Mtarget_folder = \"C:/Users/HP/Documents/Semester (summer)/Aim Lab Internship/Multi fog/M/\"  # Folder to save the converted images\n",
    "\n",
    "K_folder = \"C:/Users/HP/Documents/Semester (summer)/Aim Lab Internship/Multi fog/K/\"  # Folder containing the  K images\n",
    "Ktarget_folder = \"C:/Users/HP/Documents/Semester (summer)/Aim Lab Internship/Multi fog/K/\"  # Folder to save the converted images\n",
    "\n",
    "#for U\n",
    "# Create the target folder if it doesn't exist\n",
    "if not os.path.exists(Utarget_folder):\n",
    "    os.makedirs(Utarget_folder)\n",
    "\n",
    "# Iterate through the files in the source folder\n",
    "for filename in os.listdir(U_folder):\n",
    "    if filename.startswith(\"U080-\") and filename.endswith(\".png\"):\n",
    "        # Extract the desired part of the filename\n",
    "        new_filename = filename.split(\"-\")[1]\n",
    "\n",
    "        # Build the source and target file paths\n",
    "        source_path = os.path.join(U_folder, filename)\n",
    "        target_path = os.path.join(Utarget_folder, new_filename)\n",
    "\n",
    "        # Rename and move the file\n",
    "        os.rename(source_path, target_path)\n",
    "   \n",
    "   \n",
    "#for L     \n",
    "# Create the target folder if it doesn't exist\n",
    "if not os.path.exists(Ltarget_folder):\n",
    "    os.makedirs(Ltarget_folder)\n",
    "\n",
    "# Iterate through the files in the source folder\n",
    "for filename in os.listdir(L_folder):\n",
    "    if filename.startswith(\"L080-\") and filename.endswith(\".png\"):\n",
    "        # Extract the desired part of the filename\n",
    "        new_filename = filename.split(\"-\")[1]\n",
    "\n",
    "        # Build the source and target file paths\n",
    "        source_path = os.path.join(L_folder, filename)\n",
    "        target_path = os.path.join(Ltarget_folder, new_filename)\n",
    "\n",
    "        # Rename and move the file\n",
    "        os.rename(source_path, target_path)\n",
    "        \n",
    "   \n",
    "   \n",
    "#for Llma    \n",
    "# Create the target folder if it doesn't exist\n",
    "if not os.path.exists(Llmatarget_folder):\n",
    "    os.makedirs(Llmatarget_folder)\n",
    "\n",
    "# Iterate through the files in the source folder\n",
    "for filename in os.listdir(Llma_folder):\n",
    "    if filename.startswith(\"LIma-\") and filename.endswith(\".png\"):\n",
    "        # Extract the desired part of the filename\n",
    "        new_filename = filename.split(\"-\")[1]\n",
    "\n",
    "        # Build the source and target file paths\n",
    "        source_path = os.path.join(Llma_folder, filename)\n",
    "        target_path = os.path.join(Llmatarget_folder, new_filename)\n",
    "\n",
    "        # Rename and move the file\n",
    "        os.rename(source_path, target_path)\n",
    "        \n",
    "        \n",
    "#for M    \n",
    "# Create the target folder if it doesn't exist\n",
    "if not os.path.exists(Mtarget_folder):\n",
    "    os.makedirs(Mtarget_folder)\n",
    "\n",
    "# Iterate through the files in the source folder\n",
    "for filename in os.listdir(M_folder):\n",
    "    if filename.startswith(\"M080-\") and filename.endswith(\".png\"):\n",
    "        # Extract the desired part of the filename\n",
    "        new_filename = filename.split(\"-\")[1]\n",
    "\n",
    "        # Build the source and target file paths\n",
    "        source_path = os.path.join(M_folder, filename)\n",
    "        target_path = os.path.join(Mtarget_folder, new_filename)\n",
    "\n",
    "        # Rename and move the file\n",
    "        os.rename(source_path, target_path)\n",
    "        \n",
    "        \n",
    "        \n",
    "#for K    \n",
    "# Create the target folder if it doesn't exist\n",
    "if not os.path.exists(Ktarget_folder):\n",
    "    os.makedirs(Ktarget_folder)\n",
    "\n",
    "# Iterate through the files in the source folder\n",
    "for filename in os.listdir(K_folder):\n",
    "    if filename.startswith(\"K080-\") and filename.endswith(\".png\"):\n",
    "        # Extract the desired part of the filename\n",
    "        new_filename = filename.split(\"-\")[1]\n",
    "\n",
    "        # Build the source and target file paths\n",
    "        source_path = os.path.join(K_folder, filename)\n",
    "        target_path = os.path.join(Ktarget_folder, new_filename)\n",
    "\n",
    "        # Rename and move the file\n",
    "        os.rename(source_path, target_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 239s 17s/step - loss: 0.1183\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0707\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0659\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0591\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0578\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0618\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0582\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0596\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0560\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0598\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0611\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0588\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0622\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0567\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0570\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0567\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0589\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0576\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0618\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0558\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0565\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0650\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0561\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0862\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0618\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0567\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0559\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0626\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0600\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0547\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0535\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0518\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0528\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0525\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0523\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0536\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0539\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0508\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0493\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0546\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0628\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0584\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0542\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0598\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0503\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0556\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0492\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0543\n",
      "Epoch 49/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0545\n",
      "Epoch 50/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0532\n",
      "Epoch 51/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0480\n",
      "Epoch 52/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0481\n",
      "Epoch 53/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0454\n",
      "Epoch 54/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0477\n",
      "Epoch 55/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0572\n",
      "Epoch 56/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0484\n",
      "Epoch 57/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0530\n",
      "Epoch 58/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0518\n",
      "Epoch 59/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0489\n",
      "Epoch 60/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0493\n",
      "Epoch 61/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0471\n",
      "Epoch 62/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0457\n",
      "Epoch 63/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0467\n",
      "Epoch 64/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0447\n",
      "Epoch 65/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0528\n",
      "Epoch 66/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0537\n",
      "Epoch 67/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0463\n",
      "Epoch 68/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0477\n",
      "Epoch 69/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0453\n",
      "Epoch 70/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0477\n",
      "Epoch 71/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0440\n",
      "Epoch 72/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0515\n",
      "Epoch 73/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0439\n",
      "Epoch 74/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0531\n",
      "Epoch 75/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0441\n",
      "Epoch 76/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0464\n",
      "Epoch 77/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0432\n",
      "Epoch 78/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0461\n",
      "Epoch 79/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0445\n",
      "Epoch 80/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0443\n",
      "Epoch 81/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0529\n",
      "Epoch 82/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0477\n",
      "Epoch 83/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0494\n",
      "Epoch 84/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0542\n",
      "Epoch 85/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0513\n",
      "Epoch 86/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0454\n",
      "Epoch 87/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0434\n",
      "Epoch 88/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0475\n",
      "Epoch 89/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0457\n",
      "Epoch 90/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0458\n",
      "Epoch 91/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0464\n",
      "Epoch 92/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0424\n",
      "Epoch 93/100\n",
      "14/14 [==============================] - 224s 16s/step - loss: 0.0494\n",
      "Epoch 94/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0500\n",
      "Epoch 95/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0461\n",
      "Epoch 96/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0521\n",
      "Epoch 97/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0469\n",
      "Epoch 98/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0460\n",
      "Epoch 99/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0477\n",
      "Epoch 100/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0462\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.1217\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0666\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0664\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0601\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0710\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0610\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0698\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0683\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0578\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0595\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0577\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0588\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 223s 16s/step - loss: 0.0569\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0560\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0596\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0644\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0643\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0601\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0799\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0606\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0567\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0562\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0578\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0571\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0568\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0561\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0550\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0544\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0515\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0586\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0536\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0541\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0519\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0504\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0594\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0541\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0569\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0565\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0501\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0485\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0488\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0545\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0482\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0533\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0501\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0470\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0506\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0569\n",
      "Epoch 49/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0487\n",
      "Epoch 50/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0470\n",
      "Epoch 51/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0514\n",
      "Epoch 52/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0478\n",
      "Epoch 53/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0472\n",
      "Epoch 54/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0485\n",
      "Epoch 55/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0459\n",
      "Epoch 56/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0704\n",
      "Epoch 57/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0552\n",
      "Epoch 58/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0502\n",
      "Epoch 59/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0471\n",
      "Epoch 60/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0515\n",
      "Epoch 61/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0493\n",
      "Epoch 62/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0481\n",
      "Epoch 63/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0518\n",
      "Epoch 64/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0504\n",
      "Epoch 65/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0496\n",
      "Epoch 66/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0523\n",
      "Epoch 67/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0561\n",
      "Epoch 68/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0510\n",
      "Epoch 69/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0499\n",
      "Epoch 70/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0542\n",
      "Epoch 71/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0551\n",
      "Epoch 72/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0466\n",
      "Epoch 73/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0470\n",
      "Epoch 74/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0481\n",
      "Epoch 75/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0501\n",
      "Epoch 76/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0506\n",
      "Epoch 77/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0541\n",
      "Epoch 78/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0594\n",
      "Epoch 79/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0520\n",
      "Epoch 80/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0572\n",
      "Epoch 81/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0563\n",
      "Epoch 82/100\n",
      "14/14 [==============================] - 223s 16s/step - loss: 0.0541\n",
      "Epoch 83/100\n",
      "14/14 [==============================] - 227s 16s/step - loss: 0.0488\n",
      "Epoch 84/100\n",
      "14/14 [==============================] - 227s 16s/step - loss: 0.0491\n",
      "Epoch 85/100\n",
      "14/14 [==============================] - 226s 16s/step - loss: 0.0508\n",
      "Epoch 86/100\n",
      "14/14 [==============================] - 225s 16s/step - loss: 0.0474\n",
      "Epoch 87/100\n",
      "14/14 [==============================] - 226s 16s/step - loss: 0.0490\n",
      "Epoch 88/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0453\n",
      "Epoch 89/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0438\n",
      "Epoch 90/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0514\n",
      "Epoch 91/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0453\n",
      "Epoch 92/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0468\n",
      "Epoch 93/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0453\n",
      "Epoch 94/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0451\n",
      "Epoch 95/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0467\n",
      "Epoch 96/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0527\n",
      "Epoch 97/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0527\n",
      "Epoch 98/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0526\n",
      "Epoch 99/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0503\n",
      "Epoch 100/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0504\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.1159\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0616\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0681\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0590\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0615\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0579\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0574\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0612\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0571\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0551\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0551\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0654\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0561\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0572\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0528\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0581\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0670\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0540\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0517\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0551\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0571\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0567\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0682\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0620\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0521\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0517\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0550\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0495\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0496\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0490\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0500\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0545\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0497\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0529\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0612\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0539\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0533\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0528\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0481\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0493\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0628\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0613\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0521\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0527\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0515\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0481\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0545\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0472\n",
      "Epoch 49/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0537\n",
      "Epoch 50/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0511\n",
      "Epoch 51/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0483\n",
      "Epoch 52/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0462\n",
      "Epoch 53/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0478\n",
      "Epoch 54/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0492\n",
      "Epoch 55/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0505\n",
      "Epoch 56/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0471\n",
      "Epoch 57/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0467\n",
      "Epoch 58/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0528\n",
      "Epoch 59/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0479\n",
      "Epoch 60/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0473\n",
      "Epoch 61/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0474\n",
      "Epoch 62/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0468\n",
      "Epoch 63/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0447\n",
      "Epoch 64/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0676\n",
      "Epoch 65/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0550\n",
      "Epoch 66/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0477\n",
      "Epoch 67/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0515\n",
      "Epoch 68/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0488\n",
      "Epoch 69/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0461\n",
      "Epoch 70/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0460\n",
      "Epoch 71/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0487\n",
      "Epoch 72/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0511\n",
      "Epoch 73/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0480\n",
      "Epoch 74/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0465\n",
      "Epoch 75/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0460\n",
      "Epoch 76/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0485\n",
      "Epoch 77/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0442\n",
      "Epoch 78/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0505\n",
      "Epoch 79/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0491\n",
      "Epoch 80/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0484\n",
      "Epoch 81/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0465\n",
      "Epoch 82/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0454\n",
      "Epoch 83/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0476\n",
      "Epoch 84/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0480\n",
      "Epoch 85/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0557\n",
      "Epoch 86/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0513\n",
      "Epoch 87/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0500\n",
      "Epoch 88/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0509\n",
      "Epoch 89/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0484\n",
      "Epoch 90/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0456\n",
      "Epoch 91/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0466\n",
      "Epoch 92/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0476\n",
      "Epoch 93/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0508\n",
      "Epoch 94/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0495\n",
      "Epoch 95/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0494\n",
      "Epoch 96/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0501\n",
      "Epoch 97/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0482\n",
      "Epoch 98/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0487\n",
      "Epoch 99/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0484\n",
      "Epoch 100/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0449\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.2206\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0625\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0816\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0621\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0597\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 223s 16s/step - loss: 0.0652\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0629\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0602\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0629\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0595\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0704\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0639\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0596\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0598\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0590\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0584\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0574\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0711\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0600\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0584\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0599\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0578\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0577\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0581\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0637\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0585\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0587\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0593\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0591\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0634\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0590\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0591\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0607\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0588\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0596\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0671\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0633\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0541\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0614\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0585\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0603\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0542\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0539\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0629\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0534\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0505\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0515\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0574\n",
      "Epoch 49/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0525\n",
      "Epoch 50/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0518\n",
      "Epoch 51/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0513\n",
      "Epoch 52/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0591\n",
      "Epoch 53/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0505\n",
      "Epoch 54/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0508\n",
      "Epoch 55/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0469\n",
      "Epoch 56/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0502\n",
      "Epoch 57/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0597\n",
      "Epoch 58/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0499\n",
      "Epoch 59/100\n",
      "14/14 [==============================] - 220s 16s/step - loss: 0.0567\n",
      "Epoch 60/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0504\n",
      "Epoch 61/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0519\n",
      "Epoch 62/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0514\n",
      "Epoch 63/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0484\n",
      "Epoch 64/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0459\n",
      "Epoch 65/100\n",
      "14/14 [==============================] - 223s 16s/step - loss: 0.0525\n",
      "Epoch 66/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0738\n",
      "Epoch 67/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0518\n",
      "Epoch 68/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0517\n",
      "Epoch 69/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0520\n",
      "Epoch 70/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0479\n",
      "Epoch 71/100\n",
      "14/14 [==============================] - 227s 16s/step - loss: 0.0460\n",
      "Epoch 72/100\n",
      "14/14 [==============================] - 223s 16s/step - loss: 0.0503\n",
      "Epoch 73/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0462\n",
      "Epoch 74/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0465\n",
      "Epoch 75/100\n",
      "14/14 [==============================] - 224s 16s/step - loss: 0.0500\n",
      "Epoch 76/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0472\n",
      "Epoch 77/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0540\n",
      "Epoch 78/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0444\n",
      "Epoch 79/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0447\n",
      "Epoch 80/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0516\n",
      "Epoch 81/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0554\n",
      "Epoch 82/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0455\n",
      "Epoch 83/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0439\n",
      "Epoch 84/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0437\n",
      "Epoch 85/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0425\n",
      "Epoch 86/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0599\n",
      "Epoch 87/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0549\n",
      "Epoch 88/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0473\n",
      "Epoch 89/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0441\n",
      "Epoch 90/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0453\n",
      "Epoch 91/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0578\n",
      "Epoch 92/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0646\n",
      "Epoch 93/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0535\n",
      "Epoch 94/100\n",
      "14/14 [==============================] - 224s 16s/step - loss: 0.0485\n",
      "Epoch 95/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0488\n",
      "Epoch 96/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0451\n",
      "Epoch 97/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0438\n",
      "Epoch 98/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0437\n",
      "Epoch 99/100\n",
      "14/14 [==============================] - 221s 16s/step - loss: 0.0426\n",
      "Epoch 100/100\n",
      "14/14 [==============================] - 222s 16s/step - loss: 0.0464\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TRAINING ALL 4 MODELS\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "U_folder = \"D:/FAST_NUCES/SummerInternship/Project1_Defogging/Work/Code/FahadAttempt/Multi fog/Multi fog/U\"  # Folder containing the  U images\n",
    "L_folder = \"D:/FAST_NUCES/SummerInternship/Project1_Defogging/Work/Code/FahadAttempt/Multi fog/Multi fog/L\"  # Folder containing the  L images\n",
    "Llma_folder = \"D:/FAST_NUCES/SummerInternship/Project1_Defogging/Work/Code/FahadAttempt/Multi fog/Multi fog/Llma\"  # Folder containing the  Llma images\n",
    "M_folder = \"D:/FAST_NUCES/SummerInternship/Project1_Defogging/Work/Code/FahadAttempt/Multi fog/Multi fog/M\"  # Folder containing the  M images\n",
    "K_folder = \"D:/FAST_NUCES/SummerInternship/Project1_Defogging/Work/Code/FahadAttempt/Multi fog/Multi fog/K/\"  # Folder containing the  K images\n",
    "\n",
    "# Set the desired image size\n",
    "image_height = 480\n",
    "image_width = 640\n",
    "\n",
    "\n",
    "\"\"\" K Images Model\"\"\"\n",
    "# Load the clear and foggy images\n",
    "clear_images = []\n",
    "Kfoggy_Images = []\n",
    "for filename in os.listdir(K_folder):\n",
    "    if filename.endswith(\".png\"):\n",
    "        K_imgs = cv2.imread(os.path.join(K_folder, filename))\n",
    "        clear_filename = os.path.splitext(filename)[0] + \".png\"  # Assuming clear images have .jpg extension\n",
    "        clear_img = cv2.imread(os.path.join(Llma_folder, clear_filename))\n",
    "        K_imgs = cv2.resize(K_imgs, (image_width, image_height))\n",
    "        clear_img = cv2.resize(clear_img, (image_width, image_height))\n",
    "        Kfoggy_Images.append(K_imgs)\n",
    "        clear_images.append(clear_img)\n",
    "# Convert the lists of images to numpy arrays\n",
    "clear_images = np.array(clear_images)\n",
    "Kfoggy_Images = np.array(Kfoggy_Images)\n",
    "# Normalize pixel values to range between 0 and 1\n",
    "clear_images = clear_images.astype('float32') / 255.0\n",
    "Kfoggy_Images = Kfoggy_Images.astype('float32') / 255.0\n",
    "# Create the CNN model for K\n",
    "num_channels = 3\n",
    "modelK = Sequential()\n",
    "modelK.add(Conv2D(128, (3, 3), activation='relu', padding='same', input_shape=(image_height,image_width, num_channels)))\n",
    "modelK.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "modelK.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "modelK.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "modelK.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "modelK.add(Conv2D(num_channels, (3, 3), activation='relu', padding='same'))\n",
    "# Compile the model\n",
    "modelK.compile(optimizer='adam', loss='mean_squared_error')\n",
    "# Train the model\n",
    "modelK.fit(Kfoggy_Images, clear_images, epochs=100, batch_size=5)\n",
    "# Save the trained model\n",
    "modelK.save('trainedK_model.h5')\n",
    "\n",
    "\"\"\" L Images Model\"\"\"\n",
    "# Load the clear and foggy images\n",
    "clear_images = []\n",
    "Lfoggy_Images = []\n",
    "for filename in os.listdir(K_folder):\n",
    "    if filename.endswith(\".png\"):\n",
    "        L_imgs = cv2.imread(os.path.join(L_folder, filename))\n",
    "        clear_filename = os.path.splitext(filename)[0] + \".png\"  # Assuming clear images have .jpg extension\n",
    "        clear_img = cv2.imread(os.path.join(Llma_folder, clear_filename))\n",
    "        L_imgs = cv2.resize(L_imgs, (image_width, image_height))\n",
    "        clear_img = cv2.resize(clear_img, (image_width, image_height))\n",
    "        Lfoggy_Images.append(L_imgs)\n",
    "        clear_images.append(clear_img)\n",
    "# Convert the lists of images to numpy arrays\n",
    "clear_images = np.array(clear_images)\n",
    "Lfoggy_Images = np.array(Lfoggy_Images)\n",
    "# Normalize pixel values to range between 0 and 1\n",
    "clear_images = clear_images.astype('float32') / 255.0\n",
    "Lfoggy_Images = Lfoggy_Images.astype('float32') / 255.0\n",
    "# Create the CNN model for K\n",
    "num_channels = 3\n",
    "modelL = Sequential()\n",
    "modelL.add(Conv2D(128, (3, 3), activation='relu', padding= 'same', input_shape=(image_height,image_width, num_channels)))\n",
    "modelL.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "modelL.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "modelL.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "modelL.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "modelL.add(Conv2D(num_channels, (3, 3), activation='relu', padding='same'))\n",
    "# Compile the model\n",
    "modelL.compile(optimizer='adam', loss='mean_squared_error')\n",
    "# Train the model\n",
    "modelL.fit(Lfoggy_Images, clear_images, epochs=100, batch_size=5)\n",
    "# Save the trained model\n",
    "modelL.save('trainedL_model.h5')\n",
    "\n",
    "\n",
    "\"\"\" M Images Model\"\"\"\n",
    "# Load the clear and foggy images\n",
    "clear_images = []\n",
    "Mfoggy_Images = []\n",
    "for filename in os.listdir(M_folder):\n",
    "    if filename.endswith(\".png\"):\n",
    "        M_imgs = cv2.imread(os.path.join(M_folder, filename))\n",
    "        clear_filename = os.path.splitext(filename)[0] + \".png\"  # Assuming clear images have .jpg extension\n",
    "        clear_img = cv2.imread(os.path.join(Llma_folder, clear_filename))\n",
    "        M_imgs = cv2.resize(M_imgs, (image_width, image_height))\n",
    "        clear_img = cv2.resize(clear_img, (image_width, image_height))\n",
    "        Mfoggy_Images.append(M_imgs)\n",
    "        clear_images.append(clear_img)\n",
    "# Convert the lists of images to numpy arrays\n",
    "clear_images = np.array(clear_images)\n",
    "Mfoggy_Images = np.array(Mfoggy_Images)\n",
    "# Normalize pixel values to range between 0 and 1\n",
    "clear_images = clear_images.astype('float32') / 255.0\n",
    "Mfoggy_Images = Mfoggy_Images.astype('float32') / 255.0\n",
    "# Create the CNN model for K\n",
    "num_channels = 3\n",
    "modelM = Sequential()\n",
    "modelM.add(Conv2D(128, (3, 3), activation='relu', padding= 'same', input_shape=(image_height,image_width, num_channels)))\n",
    "modelM.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "modelM.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "modelM.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "modelM.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "modelM.add(Conv2D(num_channels, (3, 3), activation='relu', padding='same'))\n",
    "# Compile the model\n",
    "modelM.compile(optimizer='adam', loss='mean_squared_error')\n",
    "# Train the model\n",
    "modelM.fit(Mfoggy_Images, clear_images, epochs=100, batch_size=5)\n",
    "# Save the trained model\n",
    "modelM.save('trainedM_model.h5')\n",
    "\n",
    "\n",
    "\"\"\" U Images Model\"\"\"\n",
    "# Load the clear and foggy images\n",
    "clear_images = []\n",
    "Ufoggy_Images = []\n",
    "for filename in os.listdir(U_folder):\n",
    "    if filename.endswith(\".png\"):\n",
    "        U_imgs = cv2.imread(os.path.join(U_folder, filename))\n",
    "        clear_filename = os.path.splitext(filename)[0] + \".png\"  # Assuming clear images have .jpg extension\n",
    "        clear_img = cv2.imread(os.path.join(Llma_folder, clear_filename))\n",
    "        U_imgs = cv2.resize(U_imgs, (image_width, image_height))\n",
    "        clear_img = cv2.resize(clear_img, (image_width, image_height))\n",
    "        Ufoggy_Images.append(U_imgs)\n",
    "        clear_images.append(clear_img)\n",
    "# Convert the lists of images to numpy arrays\n",
    "clear_images = np.array(clear_images)\n",
    "Ufoggy_Images = np.array(Ufoggy_Images)\n",
    "# Normalize pixel values to range between 0 and 1\n",
    "clear_images = clear_images.astype('float32') / 255.0\n",
    "Ufoggy_Images = Ufoggy_Images.astype('float32') / 255.0\n",
    "# Create the CNN model for K\n",
    "num_channels = 3\n",
    "modelU = Sequential()\n",
    "modelU.add(Conv2D(128, (3, 3), activation='relu', padding= 'same', input_shape=(image_height,image_width, num_channels)))\n",
    "modelU.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "modelU.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "modelU.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "modelU.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "modelU.add(Conv2D(num_channels, (3, 3), activation='relu', padding='same'))\n",
    "# Compile the model\n",
    "modelU.compile(optimizer='adam', loss='mean_squared_error')\n",
    "# Train the model\n",
    "modelU.fit(Ufoggy_Images, clear_images, epochs=100, batch_size=5)\n",
    "# Save the trained model\n",
    "modelU.save('trainedU_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 711ms/step\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TESTING K MODEL\n",
    "\"\"\"\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "# Set the desired image size\n",
    "image_height = 480\n",
    "image_width = 640\n",
    "num_channels = 3\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(\"trainedK_model.h5\")\n",
    "\n",
    "# Load a foggy image for testing\n",
    "foggy_image_path = \"D:/FAST_NUCES/SummerInternship/Project1_Defogging/Work/Code/FahadAttempt/Multi fog/Multi fog/TestImages/foggy-001.jpg\"\n",
    "foggy_image = cv2.imread(foggy_image_path)\n",
    "\n",
    "# Resize the foggy image to the desired size\n",
    "foggy_image = cv2.resize(foggy_image, (image_width, image_height))\n",
    "\n",
    "# Preprocess the foggy image\n",
    "foggy_image = foggy_image.astype('float32') / 255.0\n",
    "foggy_image = np.expand_dims(foggy_image, axis=0)\n",
    "\n",
    "# Use the model to predict the clear image\n",
    "clear_image = model.predict(foggy_image)\n",
    "\n",
    "# Rescale the pixel values to the original range\n",
    "clear_image = clear_image * 255.0\n",
    "clear_image = clear_image.astype('uint8')\n",
    "\n",
    "# Reshape the clear image\n",
    "clear_image = np.squeeze(clear_image, axis=0)\n",
    "\n",
    "# Display the clear image\n",
    "cv2.imshow(\"Clear Image\", clear_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"d:\\Anaconda\\ActualInstallation\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function  *\n        return step_function(self, iterator)\n    File \"d:\\Anaconda\\ActualInstallation\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\Anaconda\\ActualInstallation\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step  **\n        outputs = model.predict_step(data)\n    File \"d:\\Anaconda\\ActualInstallation\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n        return self(x, training=False)\n    File \"d:\\Anaconda\\ActualInstallation\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"d:\\Anaconda\\ActualInstallation\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_3\" is incompatible with the layer: expected shape=(None, 480, 640, 3), found shape=(None, 64, 64, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1756\\2179443583.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m# Use the model to predict the clear image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mclear_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfoggy_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;31m# Rescale the pixel values to the original range\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\ActualInstallation\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\ActualInstallation\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"d:\\Anaconda\\ActualInstallation\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function  *\n        return step_function(self, iterator)\n    File \"d:\\Anaconda\\ActualInstallation\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\Anaconda\\ActualInstallation\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step  **\n        outputs = model.predict_step(data)\n    File \"d:\\Anaconda\\ActualInstallation\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n        return self(x, training=False)\n    File \"d:\\Anaconda\\ActualInstallation\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"d:\\Anaconda\\ActualInstallation\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_3\" is incompatible with the layer: expected shape=(None, 480, 640, 3), found shape=(None, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TESTING U MODEL\n",
    "\"\"\"\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "# Set the desired image size\n",
    "image_height = 480\n",
    "image_width = 640\n",
    "num_channels = 3\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(\"trainedU_model.h5\")\n",
    "\n",
    "# Load a foggy image for testing\n",
    "foggy_image_path = \"D:/FAST_NUCES/SummerInternship/Project1_Defogging/Work/Code/FahadAttempt/Multi fog/Multi fog/TestImages/foggy-001.jpg\"\n",
    "foggy_image = cv2.imread(foggy_image_path)\n",
    "\n",
    "# Resize the foggy image to the desired size\n",
    "foggy_image = cv2.resize(foggy_image, (image_width, image_height))\n",
    "\n",
    "# Preprocess the foggy image\n",
    "foggy_image = foggy_image.astype('float32') / 255.0\n",
    "foggy_image = np.expand_dims(foggy_image, axis=0)\n",
    "\n",
    "# Use the model to predict the clear image\n",
    "clear_image = model.predict(foggy_image)\n",
    "\n",
    "# Rescale the pixel values to the original range\n",
    "clear_image = clear_image * 255.0\n",
    "clear_image = clear_image.astype('uint8')\n",
    "\n",
    "# Reshape the clear image\n",
    "clear_image = np.squeeze(clear_image, axis=0)\n",
    "\n",
    "# Display the clear image\n",
    "cv2.imshow(\"Clear Image\", clear_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 334ms/step\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TESTING M MODEL\n",
    "\"\"\"\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "# Set the desired image size\n",
    "image_height = 480\n",
    "image_width = 640\n",
    "num_channels = 3\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(\"trainedM_model.h5\")\n",
    "\n",
    "# Load a foggy image for testing\n",
    "foggy_image_path = \"D:/FAST_NUCES/SummerInternship/Project1_Defogging/Work/Code/FahadAttempt/Multi fog/Multi fog/TestImages/foggy-001.jpg\"\n",
    "foggy_image = cv2.imread(foggy_image_path)\n",
    "\n",
    "# Resize the foggy image to the desired size\n",
    "foggy_image = cv2.resize(foggy_image, (image_width, image_height))\n",
    "\n",
    "# Preprocess the foggy image\n",
    "foggy_image = foggy_image.astype('float32') / 255.0\n",
    "foggy_image = np.expand_dims(foggy_image, axis=0)\n",
    "\n",
    "# Use the model to predict the clear image\n",
    "clear_image = model.predict(foggy_image)\n",
    "\n",
    "# Rescale the pixel values to the original range\n",
    "clear_image = clear_image * 255.0\n",
    "clear_image = clear_image.astype('uint8')\n",
    "\n",
    "# Reshape the clear image\n",
    "clear_image = np.squeeze(clear_image, axis=0)\n",
    "\n",
    "# Display the clear image\n",
    "cv2.imshow(\"Clear Image\", clear_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 243ms/step\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TESTING L MODEL\n",
    "\"\"\"\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "# Set the desired image size\n",
    "image_height = 480\n",
    "image_width = 640\n",
    "num_channels = 3\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(\"trainedL_model.h5\")\n",
    "\n",
    "# Load a foggy image for testing\n",
    "foggy_image_path = \"D:/FAST_NUCES/SummerInternship/Project1_Defogging/Work/Code/FahadAttempt/Multi fog/Multi fog/TestImages/foggy-001.jpg\"\n",
    "foggy_image = cv2.imread(foggy_image_path)\n",
    "\n",
    "# Resize the foggy image to the desired size\n",
    "foggy_image = cv2.resize(foggy_image, (image_width, image_height))\n",
    "\n",
    "# Preprocess the foggy image\n",
    "foggy_image = foggy_image.astype('float32') / 255.0\n",
    "foggy_image = np.expand_dims(foggy_image, axis=0)\n",
    "\n",
    "# Use the model to predict the clear image\n",
    "clear_image = model.predict(foggy_image)\n",
    "\n",
    "# Rescale the pixel values to the original range\n",
    "clear_image = clear_image * 255.0\n",
    "clear_image = clear_image.astype('uint8')\n",
    "\n",
    "# Reshape the clear image\n",
    "clear_image = np.squeeze(clear_image, axis=0)\n",
    "\n",
    "# Display the clear image\n",
    "cv2.imshow(\"Clear Image\", clear_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Set the path to the original image folder\n",
    "original_folder = 'C:/Users/HP/Documents/Semester (summer)/Aim Lab Internship/Multi fog/K/'\n",
    "# Set the path to the folder where augmented images will be saved\n",
    "augmented_folder = 'C:/Users/HP/Documents/Semester (summer)/Aim Lab Internship/Multi fog/K/Generated/'\n",
    "\n",
    "# Create the augmented images folder within the original image folder\n",
    "new_folder = os.path.join(original_folder, 'augmented')\n",
    "os.makedirs(new_folder, exist_ok=True)\n",
    "\n",
    "# Set the desired augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    zoom_range=0.1\n",
    ")\n",
    "\n",
    "# Iterate through the images in the original folder and generate augmented images\n",
    "for filename in os.listdir(original_folder):\n",
    "    if filename.endswith('.png'):  # Adjust the file extension if necessary\n",
    "        img_path = os.path.join(original_folder, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "\n",
    "        # Reshape the image to have a batch dimension\n",
    "        img = img.reshape((1,) + img.shape)\n",
    "\n",
    "        # Generate augmented images\n",
    "        augmented_images = datagen.flow(img, batch_size=1, save_to_dir=new_folder, save_prefix='aug_', save_format='png')\n",
    "\n",
    "        # Generate and save the augmented images\n",
    "        for i, augmented_image in enumerate(augmented_images):\n",
    "            if i >= 10:  # Generate 10 augmented images per original image\n",
    "                break\n",
    "\n",
    "# Confirm completion\n",
    "print('Data augmentation complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Image Augmentation \n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Set the path to the original image folder\n",
    "original_folder = 'path_to_original_images_folder'\n",
    "# Set the path to the folder where augmented images will be saved\n",
    "augmented_folder = 'path_to_augmented_images_folder'\n",
    "\n",
    "# Create the augmented images folder within the original image folder\n",
    "new_folder = os.path.join(original_folder, 'augmented')\n",
    "os.makedirs(new_folder, exist_ok=True)\n",
    "\n",
    "# Set the desired augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    zoom_range=0.1\n",
    ")\n",
    "\n",
    "# Iterate through the images in the original folder and generate augmented images\n",
    "for filename in os.listdir(original_folder):\n",
    "    if filename.endswith('.png'):  # Adjust the file extension if necessary\n",
    "        img_path = os.path.join(original_folder, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "\n",
    "        # Reshape the image to have a batch dimension\n",
    "        img = img.reshape((1,) + img.shape)\n",
    "\n",
    "        # Generate augmented images\n",
    "        augmented_images = datagen.flow(img, batch_size=1, save_to_dir=new_folder, save_prefix='aug_', save_format='png')\n",
    "\n",
    "        # Generate and save the augmented images\n",
    "        num_augmented = 0\n",
    "        for augmented_image in augmented_images:\n",
    "            num_augmented += 1\n",
    "            if num_augmented >= 10:  # Generate 10 augmented images per original image\n",
    "                break\n",
    "\n",
    "        # Break the loop if the desired number of augmented images is reached\n",
    "\n",
    "# Confirm completion\n",
    "print('Data augmentation complete.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
